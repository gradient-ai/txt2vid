{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!bash setup.sh\n",
    "import os\n",
    "os._exit(00)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:30:06.806210Z",
     "iopub.status.busy": "2023-03-23T23:30:06.805571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!huggingface-cli login"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate video from text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os, subprocess\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.outputs import OutputKeys\n",
    "import pathlib\n",
    "import torch\n",
    "torch.manual_seed(468)\n",
    "\n",
    "model_dir = pathlib.Path('/notebooks/modelscope-damo-text-to-video-synthesis')\n",
    "\n",
    "if not os.path.exists('modelscope-damo-text-to-video-synthesis'):\n",
    "    snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis', repo_type='model', local_dir=model_dir)\n",
    "    subprocess.run(['cp', 'configuration.json', 'modelscope-damo-text-to-video-synthesis/configuration.json'])\n",
    "\n",
    "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix(),output_video = 'outs/video.mp4')\n",
    "test_text = {\n",
    "        'text': 'Alice in Wonderland animated disney princess dancing',\n",
    "        'output_video_path' : 'outs/video.mp4'\n",
    "    }\n",
    "output_video_path = pipe(test_text,output_video = 'outs/video.mp4')[OutputKeys.OUTPUT_VIDEO]\n",
    "print('output_video_path:', output_video_path)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:32:36.558621Z",
     "iopub.status.busy": "2023-03-23T23:32:36.558328Z",
     "iopub.status.idle": "2023-03-23T23:37:01.993821Z",
     "shell.execute_reply": "2023-03-23T23:37:01.992994Z",
     "shell.execute_reply.started": "2023-03-23T23:32:36.558589Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Speech from voice sample and text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## Alice\n",
    "!yt-dlp --extract-audio --audio-format wav https://www.youtube.com/watch?v=Srn0xkXTSgs --output TTS/audio_samps/alice.wav\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Srn0xkXTSgs\n",
      "[youtube] Srn0xkXTSgs: Downloading webpage\n",
      "[youtube] Srn0xkXTSgs: Downloading android player API JSON\n",
      "[info] Srn0xkXTSgs: Downloading 1 format(s): 251\n",
      "[download] TTS/audio_samps/alice.wav has already been downloaded\n",
      "[ExtractAudio] Destination: TTS/audio_samps/alice.wav\n",
      "Deleting original file TTS/audio_samps/alice.orig.wav (pass -k to keep)\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:37:01.995687Z",
     "iopub.status.busy": "2023-03-23T23:37:01.995440Z",
     "iopub.status.idle": "2023-03-23T23:37:04.627246Z",
     "shell.execute_reply": "2023-03-23T23:37:04.626246Z",
     "shell.execute_reply.started": "2023-03-23T23:37:01.995664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False, gpu=True)\n",
    "tts.tts_to_file('Oh what a lovely day to be outside!', speaker_wav=\"/notebooks/TTS/audio_samps/alice.wav\", language=\"en\", file_path=\"outs/speech.wav\")\n"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:37:04.631509Z",
     "iopub.status.busy": "2023-03-23T23:37:04.631306Z",
     "iopub.status.idle": "2023-03-23T23:37:19.898049Z",
     "shell.execute_reply": "2023-03-23T23:37:19.897050Z",
     "shell.execute_reply.started": "2023-03-23T23:37:04.631486Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate background music from text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from spectro import wav_bytes_from_spectrogram_image\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import gradio as gr\n",
    "device = \"cuda\"\n",
    "MODEL_ID = \"riffusion/riffusion-model-v1\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(MODEL_ID, torch_dtype=torch.float16)\n",
    "pipe2 = pipe2.to(device)\n",
    "\n",
    "spectro_from_wav = gr.Interface.load(\"spaces/fffiloni/audio-to-spectrogram\")\n",
    "\n",
    "def predict(prompt, negative_prompt, audio_input, duration):\n",
    "    if audio_input == None :\n",
    "        return classic(prompt, negative_prompt, duration)\n",
    "    else :\n",
    "        return style_transfer(prompt, negative_prompt, audio_input)\n",
    "\n",
    "def classic(prompt, negative_prompt, duration):\n",
    "    if duration == 5:\n",
    "        width_duration=512\n",
    "    else :\n",
    "        width_duration = 512 + ((int(duration)-5) * 128)\n",
    "    spec = pipe(prompt, negative_prompt=negative_prompt, height=512, width=width_duration).images[0]\n",
    "    print(spec)\n",
    "    wav = wav_bytes_from_spectrogram_image(spec)\n",
    "    with open(\"outs/music.wav\", \"wb\") as f:\n",
    "        f.write(wav[0].getbuffer())\n",
    "    return spec, 'outs/music.wav', gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
    "\n",
    "def style_transfer(prompt, negative_prompt, audio_input):\n",
    "    spec = spectro_from_wav(audio_input)\n",
    "    print(spec)\n",
    "    # Open the image\n",
    "    im = Image.open(spec)\n",
    "    \n",
    "    \n",
    "    # Open the image\n",
    "    im = image_from_spectrogram(im, 1)\n",
    "   \n",
    "    \n",
    "    new_spectro = pipe2(prompt=prompt, image=im, strength=0.5, guidance_scale=7).images\n",
    "    wav = wav_bytes_from_spectrogram_image(new_spectro[0])\n",
    "    with open(\"outs/music.wav\", \"wb\") as f:\n",
    "        f.write(wav[0].getbuffer())\n",
    "    return new_spectro[0], 'outs/music.wav', gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
    "\n",
    "def image_from_spectrogram(\n",
    "    spectrogram: np.ndarray, max_volume: float = 50, power_for_image: float = 0.25\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Compute a spectrogram image from a spectrogram magnitude array.\n",
    "    \"\"\"\n",
    "    # Apply the power curve\n",
    "    data = np.power(spectrogram, power_for_image)\n",
    "\n",
    "    # Rescale to 0-255\n",
    "    data = data * 255 / max_volume\n",
    "\n",
    "    # Invert\n",
    "    data = 255 - data\n",
    "\n",
    "    # Convert to a PIL image\n",
    "    image = Image.fromarray(data.astype(np.uint8))\n",
    "\n",
    "    # Flip Y\n",
    "    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    # Convert to RGB\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "prompt_input = 'a disney theme song'\n",
    "negative_prompt = ''\n",
    "audio_input = None\n",
    "duration_input = 5\n",
    "    \n",
    "spectrogram_output, sound_output, share_button, community_icon, loading_icon = predict(prompt_input, negative_prompt, audio_input, duration_input)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:37:19.901523Z",
     "iopub.status.busy": "2023-03-23T23:37:19.901346Z",
     "iopub.status.idle": "2023-03-23T23:38:29.329645Z",
     "shell.execute_reply": "2023-03-23T23:38:29.328780Z",
     "shell.execute_reply.started": "2023-03-23T23:37:19.901502Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composite audio and video files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from moviepy.editor import *\n",
    "# load the video\n",
    "video_clip = VideoFileClip('outs/video.mp4')\n",
    "# # load the audio\n",
    "music_clip = AudioFileClip('outs/music.wav')\n",
    "speech_clip = AudioFileClip('outs/speech.wav')\n",
    "\n",
    "\n",
    "new_audioclip = CompositeAudioClip([music_clip, speech_clip])\n",
    "video_clip.audio = new_audioclip\n",
    "video_clip.write_videofile(\"outs/final.mp4\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:38:29.335041Z",
     "iopub.status.busy": "2023-03-23T23:38:29.334527Z",
     "iopub.status.idle": "2023-03-23T23:38:31.975647Z",
     "shell.execute_reply": "2023-03-23T23:38:31.974753Z",
     "shell.execute_reply.started": "2023-03-23T23:38:29.335015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"outs/final.mp4\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:38:31.979222Z",
     "iopub.status.busy": "2023-03-23T23:38:31.979007Z",
     "iopub.status.idle": "2023-03-23T23:38:31.984271Z",
     "shell.execute_reply": "2023-03-23T23:38:31.983707Z",
     "shell.execute_reply.started": "2023-03-23T23:38:31.979196Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradio"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python app.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}